{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDcjXpzcLFf9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the basic residual block\n",
        "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=False):\n",
        "    shortcut = x\n",
        "\n",
        "    # First convolution layer\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Second convolution layer\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Shortcut connection\n",
        "    if conv_shortcut:\n",
        "        shortcut = layers.Conv2D(filters, 1, strides=stride, padding='same')(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "yEWFhPG8LPnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet18(input_shape=(224, 224, 3), num_classes=1):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolution layer\n",
        "    x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    x = residual_block(x, 64, conv_shortcut=True)\n",
        "    x = residual_block(x, 64)\n",
        "\n",
        "    x = residual_block(x, 128, stride=2, conv_shortcut=True)\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    x = residual_block(x, 256, stride=2, conv_shortcut=True)\n",
        "    x = residual_block(x, 256)\n",
        "\n",
        "    x = residual_block(x, 512, stride=2, conv_shortcut=True)\n",
        "    x = residual_block(x, 512)\n",
        "\n",
        "    # Fully connected layer\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation='sigmoid')(x)  # Sigmoid for binary classification\n",
        "\n",
        "    model = models.Model(inputs, x)\n",
        "    return model"
      ],
      "metadata": {
        "id": "oH5yIM65LSY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to your dataset\n",
        "train_dir = 'path_to_train_images'\n",
        "val_dir = 'path_to_val_images'\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "# Load datasets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Binary classification\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "u1BCDXgoLT6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = build_resnet18(input_shape=(224, 224, 3))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',  # Binary classification loss\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "2o3IHoqmLVHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "GKZJYGU3LWO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('resnet18_crack_detection.h5')"
      ],
      "metadata": {
        "id": "8as3ux_JLXRI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}